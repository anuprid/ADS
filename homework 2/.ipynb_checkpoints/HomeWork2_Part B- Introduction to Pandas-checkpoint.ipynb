{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='heading'>\n",
    "    <div style='float:left;'><h1>CPSC 4300/6300: Applied Data Science</h1></div>\n",
    "    <img style=\"float: right; padding-right: 10px; width: 65px\" src=\"https://raw.githubusercontent.com/bsethwalker/clemson-cs4300/main/images/clemson_paw.png\"> </div><br>\n",
    "\n",
    "\n",
    "## Week 2: Introduction to Pandas\n",
    "\n",
    "**Clemson University**<br>\n",
    "**Spring 2024**<br>\n",
    "**Instructor(s):** Nina Hubig <br>\n",
    "**TA(s):** Luyi Li\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "\n",
       "div.heading {\n",
       "margin-bottom: 25px;\n",
       "height: 75px;\n",
       "}\n",
       "\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "    \n",
       "    background: rgba(245, 102, 0, .75);\n",
       "    border-color: #E9967A;\n",
       "    border-left: 5px solid #522D80; \n",
       "    padding: 0.5em;\n",
       "}\n",
       "\n",
       "div.exercise-r {\n",
       "    background-color: #fce8e8;\n",
       "    border-color: #E9967A; \t\n",
       "    border-left: 5px solid #800080; \n",
       "    padding: 0.5em;\n",
       "}\n",
       "\n",
       "span.sub-q {\n",
       "    font-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "    background-color: #DDDDDD;\n",
       "    border-color: #E9967A; \t\n",
       "    border-left: 5px solid #800080; \n",
       "    padding: 0.5em;\n",
       "    font-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "    background-color: #AEDE94;\n",
       "    border-color: #E9967A; \t \n",
       "    border-left: 5px solid #800080; \n",
       "    padding: 0.5em;\n",
       "    font-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" RUN THIS CELL TO GET THE RIGHT FORMATTING \"\"\"\n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "css_file = 'https://raw.githubusercontent.com/bsethwalker/clemson-cs4300/main/css/cpsc6300.css'\n",
    "styles = requests.get(css_file).text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents \n",
    "<ol start=\"0\">\n",
    "<li> Learning Goals </li>\n",
    "<li> Loading and Cleaning with Pandas</li>\n",
    "<li> Parsing and Completing the Dataframe  </li>\n",
    "<li> Grouping </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "\n",
    "About 6,000 odd \"best books\" were fetched and parsed from [Goodreads](https://www.goodreads.com). The \"bestness\" of these books came from a proprietary formula used by Goodreads and published as a list on their web site.\n",
    "\n",
    "We parsed the page for each book and saved data from all these pages in a tabular format as a CSV file. In this lab we'll clean and further parse the data.  We'll then do some exploratory data analysis to answer questions about these best books and popular genres.  \n",
    "\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "\n",
    "- Load and systematically address missing values, encoded as `NaN` values in our data set, for example, by removing observations associated with these values.\n",
    "- Parse columns in the dataframe to create new dataframe columns.\n",
    "- Use groupby to aggregate data on a particular feature column, such as author."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic EDA workflow\n",
    "\n",
    "The basic workflow is as follows:\n",
    "\n",
    "1. **Build** a DataFrame from the data (ideally, put all data in this object)\n",
    "2. **Clean** the DataFrame. It should have the following properties:\n",
    "    - Each row describes a single object\n",
    "    - Each column describes a property of that object\n",
    "    - Columns are numeric whenever appropriate\n",
    "    - Columns contain atomic properties that cannot be further decomposed\n",
    "3. Explore **global properties**. Use histograms, scatter plots, and aggregation functions to summarize the data.\n",
    "4. Explore **group properties**. Use groupby and small multiples to compare subsets of the data.\n",
    "\n",
    "This process transforms your data into a format which is easier to work with, gives you a basic overview of the data's properties, and likely generates several questions for you to followup in subsequent analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Loading and Cleaning with Pandas \n",
    "Read in the `goodreads.csv` file, examine the data, and do any necessary data cleaning. \n",
    "\n",
    "Here is a description of the columns (in order) present in this csv file:\n",
    "\n",
    "```\n",
    "rating: the average rating on a 1-5 scale achieved by the book\n",
    "review_count: the number of Goodreads users who reviewed this book\n",
    "isbn: the ISBN code for the book\n",
    "booktype: an internal Goodreads identifier for the book\n",
    "author_url: the Goodreads (relative) URL for the author of the book\n",
    "year: the year the book was published\n",
    "genre_urls: a string with '|' separated relative URLS of Goodreads genre pages\n",
    "dir: a directory identifier internal to the scraping code\n",
    "rating_count: the number of ratings for this book (this is different from the number of reviews)\n",
    "name: the name of the book\n",
    "```\n",
    "\n",
    "Let us see what issues we find with the data and resolve them.  \n",
    "\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "After loading appropriate libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning: Reading in the data\n",
    "We read in and clean the data from `goodreads.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/goodreads.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Read the data into a dataframe\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/goodreads.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#Examine the first few rows of the dataframe\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AppliedDataScience/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AppliedDataScience/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AppliedDataScience/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AppliedDataScience/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AppliedDataScience/lib/python3.11/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/goodreads.csv'"
     ]
    }
   ],
   "source": [
    "#Read the data into a dataframe\n",
    "df = pd.read_csv(\"data/goodreads.csv\", encoding='utf-8')\n",
    "\n",
    "#Examine the first few rows of the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh dear. That does not quite seem to be right. We are missing the column names. We need to add these in! But what are they?\n",
    "\n",
    "Here is a list of them in order:\n",
    "\n",
    "`[\"rating\", 'review_count', 'isbn', 'booktype','author_url', 'year', 'genre_urls', 'dir','rating_count', 'name']`\n",
    "\n",
    "<div class=\"exercise\"><b>Exercise 1</b></div>\n",
    "Use these to load the dataframe properly! And then \"head\" the dataframe... (you will need to look at the read_csv docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>booktype</th>\n",
       "      <th>author_url</th>\n",
       "      <th>year</th>\n",
       "      <th>genre_urls</th>\n",
       "      <th>dir</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.40</td>\n",
       "      <td>136455.0</td>\n",
       "      <td>0439023483</td>\n",
       "      <td>good_reads:book</td>\n",
       "      <td>https://www.goodreads.com/author/show/153394.S...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>/genres/young-adult|/genres/science-fiction|/g...</td>\n",
       "      <td>dir01/2767052-the-hunger-games.html</td>\n",
       "      <td>2958974.0</td>\n",
       "      <td>The Hunger Games (The Hunger Games, #1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.41</td>\n",
       "      <td>16648.0</td>\n",
       "      <td>0439358078</td>\n",
       "      <td>good_reads:book</td>\n",
       "      <td>https://www.goodreads.com/author/show/1077326....</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>/genres/fantasy|/genres/young-adult|/genres/fi...</td>\n",
       "      <td>dir01/2.Harry_Potter_and_the_Order_of_the_Phoe...</td>\n",
       "      <td>1284478.0</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.56</td>\n",
       "      <td>85746.0</td>\n",
       "      <td>0316015849</td>\n",
       "      <td>good_reads:book</td>\n",
       "      <td>https://www.goodreads.com/author/show/941441.S...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>/genres/young-adult|/genres/fantasy|/genres/ro...</td>\n",
       "      <td>dir01/41865.Twilight.html</td>\n",
       "      <td>2579564.0</td>\n",
       "      <td>Twilight (Twilight, #1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.23</td>\n",
       "      <td>47906.0</td>\n",
       "      <td>0061120081</td>\n",
       "      <td>good_reads:book</td>\n",
       "      <td>https://www.goodreads.com/author/show/1825.Har...</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>/genres/classics|/genres/fiction|/genres/histo...</td>\n",
       "      <td>dir01/2657.To_Kill_a_Mockingbird.html</td>\n",
       "      <td>2078123.0</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  review_count        isbn         booktype                                         author_url    year                                         genre_urls                                                dir  rating_count                                               name\n",
       "0    4.40      136455.0  0439023483  good_reads:book  https://www.goodreads.com/author/show/153394.S...  2008.0  /genres/young-adult|/genres/science-fiction|/g...                dir01/2767052-the-hunger-games.html     2958974.0            The Hunger Games (The Hunger Games, #1)\n",
       "1    4.41       16648.0  0439358078  good_reads:book  https://www.goodreads.com/author/show/1077326....  2003.0  /genres/fantasy|/genres/young-adult|/genres/fi...  dir01/2.Harry_Potter_and_the_Order_of_the_Phoe...     1284478.0  Harry Potter and the Order of the Phoenix (Har...\n",
       "2    3.56       85746.0  0316015849  good_reads:book  https://www.goodreads.com/author/show/941441.S...  2005.0  /genres/young-adult|/genres/fantasy|/genres/ro...                          dir01/41865.Twilight.html     2579564.0                            Twilight (Twilight, #1)\n",
       "3    4.23       47906.0  0061120081  good_reads:book  https://www.goodreads.com/author/show/1825.Har...  1960.0  /genres/classics|/genres/fiction|/genres/histo...              dir01/2657.To_Kill_a_Mockingbird.html     2078123.0                              To Kill a Mockingbird"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "#Examine the first few rows of the dataframe\n",
    "df = pd.read_csv(\"goodreads.csv\", header= None) \n",
    "# add column names\n",
    "df.columns =['rating', 'review_count', 'isbn', 'booktype', 'author_url', 'year', 'genre_urls', 'dir', 'rating_count', 'name']\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning: Examing the dataframe - quick checks\n",
    "\n",
    "We should examine the dataframe to get a overall sense of the content. \n",
    "\n",
    "<div class=\"exercise\"><b>Exercise 2</b></div>\n",
    "Lets check the types of the columns. What do you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating          float64\n",
       "review_count    float64\n",
       "isbn             object\n",
       "booktype         object\n",
       "author_url       object\n",
       "year            float64\n",
       "genre_urls       object\n",
       "dir              object\n",
       "rating_count    float64\n",
       "name             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "Notice that `review_count` and `rating_counts` are objects instead of ints, and the `year` is a float!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple more quick sanity checks to perform on the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['rating', 'review_count', 'isbn', 'booktype', 'author_url', 'year', 'genre_urls', 'dir', 'rating_count', 'name'], dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning: Examining the dataframe - a deeper look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond performing checking some quick general properties of the data frame and looking at the first $n$ rows, we can dig a bit deeper into the values being stored. If you haven't already, check to see if there are any missing values in the data frame.\n",
    "\n",
    "Let's see for a column which seemed OK to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "477\n",
      "2\n",
      "2\n",
      "7\n",
      "62\n",
      "0\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#Get a sense of how many missing values there are in the dataframe.\n",
    "print(np.sum([df.rating.isnull()]))\n",
    "print(np.sum([df.review_count.isnull()]))\n",
    "print(np.sum([df.isbn.isnull()]))\n",
    "print(np.sum([df.booktype.isnull()]))\n",
    "print(np.sum([df.author_url.isnull()]))\n",
    "print(np.sum([df.year.isnull()]))\n",
    "print(np.sum([df.genre_urls.isnull()]))\n",
    "print(np.sum([df.dir.isnull()]))\n",
    "print(np.sum([df.rating_count.isnull()]))\n",
    "print(np.sum([df.name.isnull()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>booktype</th>\n",
       "      <th>author_url</th>\n",
       "      <th>year</th>\n",
       "      <th>genre_urls</th>\n",
       "      <th>dir</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3643</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dir37/9658936-harry-potter.html</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5282</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dir53/113138.The_Winner.html</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating  review_count isbn booktype author_url  year genre_urls                              dir  rating_count name\n",
       "3643     NaN           NaN  NaN      NaN        NaN   NaN        NaN  dir37/9658936-harry-potter.html           NaN  NaN\n",
       "5282     NaN           NaN  NaN      NaN        NaN   NaN        NaN     dir53/113138.The_Winner.html           NaN  NaN"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try to locate where the missing values occur\n",
    "df[df.rating.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does `pandas` or `numpy` handle missing values when we try to compute with data sets that include them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now check if any of the other suspicious columns have missing values.  Let's look at `year` and `review_count` first.\n",
    "\n",
    "One thing you can do is to try and convert to the type you expect the column to be. If something goes wrong, it likely means your data are bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test for missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 10)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.year.isnull()]\n",
    "\n",
    "df.year.isnull()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning: Dealing with Missing Values\n",
    "How should we interpret 'missing' or 'invalid' values in the data (hint: look at where these values occur)? One approach is to simply exclude them from the dataframe. Is this appropriate for all 'missing' or 'invalid' values? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treat the missing or invalid values in your dataframe\n",
    "####### \n",
    "\n",
    "df = df[df.year.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so we have done some cleaning. What do things look like now? Notice the float has not yet changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating          float64\n",
       "review_count    float64\n",
       "isbn             object\n",
       "booktype         object\n",
       "author_url       object\n",
       "year            float64\n",
       "genre_urls       object\n",
       "dir              object\n",
       "rating_count    float64\n",
       "name             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5993, 10)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.sum(df.year.isnull()))\n",
    "df.shape # We removed seven rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 3</b></div>\n",
    "\n",
    "Ok so lets fix those types. Convert them to ints. If the type conversion fails, we now know we have further problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "df['review_count'] = df['review_count'].astype(int)\n",
    "df['year'] = df['year'].astype(int)\n",
    "df['rating_count'] = df['rating_count'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you do this, we seem to be good on these columns (no errors in conversion). Lets look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating          float64\n",
       "review_count      int64\n",
       "isbn             object\n",
       "booktype         object\n",
       "author_url       object\n",
       "year              int64\n",
       "genre_urls       object\n",
       "dir              object\n",
       "rating_count      int64\n",
       "name             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the other colums that should be strings have NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.genre_urls.isnull(), 'genre_urls']=\"\"\n",
    "df.loc[df.isbn.isnull(), 'isbn']=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 2: Parsing and Completing the Data Frame \n",
    "\n",
    "We will parse the `author` column from the author_url and `genres` column from the genre_urls. Keep the `genres` column as a string separated by '|'.\n",
    "\n",
    "We will use panda's `map` to assign new columns to the dataframe.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine an example `author_url` and reason about which sequence of string operations must be performed in order to isolate the author's name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.goodreads.com/author/show/153394.Suzanne_Collins'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the first author_url\n",
    "test_string = df.author_url[0]\n",
    "test_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Suzanne_Collins'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test out some string operations to isolate the author name\n",
    "\n",
    "test_string.split('/')[-1].split('.')[1:][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 4</b></div>\n",
    "\n",
    "Lets wrap the above code into a function which we will then use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suzanne_Collins\n"
     ]
    }
   ],
   "source": [
    "# Write a function that accepts an author url and returns the author's name based on your experimentation above\n",
    "def get_author(url):\n",
    "    # your code here\n",
    "    name = url.split('/')[-1].split('.')[1:][0]\n",
    "    return name\n",
    "print(get_author(df.author_url[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Suzanne_Collins\n",
       "1        J_K_Rowling\n",
       "2    Stephenie_Meyer\n",
       "3         Harper_Lee\n",
       "4        Jane_Austen\n",
       "Name: author, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply the get_author function to the 'author_url' column using '.map' \n",
    "#and add a new column 'author' to store the names\n",
    "df['author'] = df.author_url.map(get_author)\n",
    "df.author[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now parse out the genres from `genre_url`.  \n",
    "\n",
    "This is a little more complicated because there be more than one genre.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    /genres/young-adult|/genres/science-fiction|/g...\n",
       "1    /genres/fantasy|/genres/young-adult|/genres/fi...\n",
       "2    /genres/young-adult|/genres/fantasy|/genres/ro...\n",
       "3    /genres/classics|/genres/fiction|/genres/histo...\n",
       "4    /genres/classics|/genres/fiction|/genres/roman...\n",
       "Name: genre_urls, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.genre_urls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "young-adult\n",
      "science-fiction\n",
      "dystopia\n",
      "fantasy\n",
      "science-fiction\n",
      "romance\n",
      "adventure\n",
      "book-club\n",
      "young-adult\n",
      "teen\n",
      "apocalyptic\n",
      "post-apocalyptic\n",
      "action\n"
     ]
    }
   ],
   "source": [
    "#Examine some examples of genre_urls\n",
    "\n",
    "#Test out some string operations to isolate the genre name\n",
    "test_genre_string=df.genre_urls[0]\n",
    "genres=test_genre_string.strip().split('|')\n",
    "for e in genres:\n",
    "    print(e.split('/')[-1])\n",
    "    \"|\".join(genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 5</b></div>\n",
    "\n",
    "Write a function that accepts a genre url and returns the genre name based on your experimentation above\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_join_genres(url):\n",
    "    # your code here\n",
    "    genres = url.strip().split('|')\n",
    "    for e in genres:\n",
    "        print(e.split('/')[-1])\n",
    "        \"|\".join(genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "young-adult\n",
      "science-fiction\n"
     ]
    }
   ],
   "source": [
    "split_and_join_genres(\"/genres/young-adult|/genres/science-fiction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "split_and_join_genres(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This question is primarily aimed at graduate students, serving as a critical part of their assignment. However, undergraduate students are encouraged to take this on as an optional bonus challenge.\n",
    "<div class=\"exercise\"><b>Exercise 6</b></div>\n",
    "Use map again to create a new \"genres\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "young-adult\n",
      "science-fiction\n",
      "dystopia\n",
      "fantasy\n",
      "science-fiction\n",
      "romance\n",
      "adventure\n",
      "book-club\n",
      "young-adult\n",
      "teen\n",
      "apocalyptic\n",
      "post-apocalyptic\n",
      "action\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>booktype</th>\n",
       "      <th>author_url</th>\n",
       "      <th>year</th>\n",
       "      <th>genre_urls</th>\n",
       "      <th>dir</th>\n",
       "      <th>genres</th>\n",
       "      <th>genres</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>name</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>136455</td>\n",
       "      <td>0439023483</td>\n",
       "      <td>good_reads:book</td>\n",
       "      <td>https://www.goodreads.com/author/show/153394.S...</td>\n",
       "      <td>2008</td>\n",
       "      <td>/genres/young-adult|/genres/science-fiction|/g...</td>\n",
       "      <td>dir01/2767052-the-hunger-games.html</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2958974</td>\n",
       "      <td>The Hunger Games (The Hunger Games, #1)</td>\n",
       "      <td>Suzanne_Collins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>16648</td>\n",
       "      <td>0439358078</td>\n",
       "      <td>good_reads:book</td>\n",
       "      <td>https://www.goodreads.com/author/show/1077326....</td>\n",
       "      <td>2003</td>\n",
       "      <td>/genres/fantasy|/genres/young-adult|/genres/fi...</td>\n",
       "      <td>dir01/2.Harry_Potter_and_the_Order_of_the_Phoe...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1284478</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Har...</td>\n",
       "      <td>J_K_Rowling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>85746</td>\n",
       "      <td>0316015849</td>\n",
       "      <td>good_reads:book</td>\n",
       "      <td>https://www.goodreads.com/author/show/941441.S...</td>\n",
       "      <td>2005</td>\n",
       "      <td>/genres/young-adult|/genres/fantasy|/genres/ro...</td>\n",
       "      <td>dir01/41865.Twilight.html</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2579564</td>\n",
       "      <td>Twilight (Twilight, #1)</td>\n",
       "      <td>Stephenie_Meyer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>47906</td>\n",
       "      <td>0061120081</td>\n",
       "      <td>good_reads:book</td>\n",
       "      <td>https://www.goodreads.com/author/show/1825.Har...</td>\n",
       "      <td>1960</td>\n",
       "      <td>/genres/classics|/genres/fiction|/genres/histo...</td>\n",
       "      <td>dir01/2657.To_Kill_a_Mockingbird.html</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2078123</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper_Lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>34772</td>\n",
       "      <td>0679783261</td>\n",
       "      <td>good_reads:book</td>\n",
       "      <td>https://www.goodreads.com/author/show/1265.Jan...</td>\n",
       "      <td>1813</td>\n",
       "      <td>/genres/classics|/genres/fiction|/genres/roman...</td>\n",
       "      <td>dir01/1885.Pride_and_Prejudice.html</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1388992</td>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Jane_Austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  review_count        isbn         booktype                                         author_url  year                                         genre_urls                                                dir genres genres genres  rating_count                                               name           author\n",
       "0     4.0        136455  0439023483  good_reads:book  https://www.goodreads.com/author/show/153394.S...  2008  /genres/young-adult|/genres/science-fiction|/g...                dir01/2767052-the-hunger-games.html   None   None   None       2958974            The Hunger Games (The Hunger Games, #1)  Suzanne_Collins\n",
       "1     4.0         16648  0439358078  good_reads:book  https://www.goodreads.com/author/show/1077326....  2003  /genres/fantasy|/genres/young-adult|/genres/fi...  dir01/2.Harry_Potter_and_the_Order_of_the_Phoe...   None   None   None       1284478  Harry Potter and the Order of the Phoenix (Har...      J_K_Rowling\n",
       "2     3.0         85746  0316015849  good_reads:book  https://www.goodreads.com/author/show/941441.S...  2005  /genres/young-adult|/genres/fantasy|/genres/ro...                          dir01/41865.Twilight.html   None   None   None       2579564                            Twilight (Twilight, #1)  Stephenie_Meyer\n",
       "3     4.0         47906  0061120081  good_reads:book  https://www.goodreads.com/author/show/1825.Har...  1960  /genres/classics|/genres/fiction|/genres/histo...              dir01/2657.To_Kill_a_Mockingbird.html   None   None   None       2078123                              To Kill a Mockingbird       Harper_Lee\n",
       "4     4.0         34772  0679783261  good_reads:book  https://www.goodreads.com/author/show/1265.Jan...  1813  /genres/classics|/genres/fiction|/genres/roman...                dir01/1885.Pride_and_Prejudice.html   None   None   None       1388992                                Pride and Prejudice      Jane_Austen"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.insert(8,'genres',split_and_join_genres(df.genre_urls[0]), True)\n",
    "# your code here\n",
    "genres = split_and_join_genres(df.genre_urls[0])\n",
    "df['genres'] = genres\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's pick an author at random so we can see the results of the transformations.  Scroll to see the `author` and `genre` columns that we added to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>booktype</th>\n",
       "      <th>author_url</th>\n",
       "      <th>year</th>\n",
       "      <th>genre_urls</th>\n",
       "      <th>dir</th>\n",
       "      <th>genres</th>\n",
       "      <th>genres</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>name</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>4.0</td>\n",
       "      <td>483</td>\n",
       "      <td>0374529264</td>\n",
       "      <td>good_reads:book</td>\n",
       "      <td>https://www.goodreads.com/author/show/7732.Mar...</td>\n",
       "      <td>1951</td>\n",
       "      <td>/genres/historical-fiction|/genres/fiction|/ge...</td>\n",
       "      <td>dir11/12172.Memoirs_of_Hadrian.html</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>6258</td>\n",
       "      <td>Memoirs of Hadrian</td>\n",
       "      <td>Marguerite_Yourcenar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5620</th>\n",
       "      <td>4.0</td>\n",
       "      <td>74</td>\n",
       "      <td>2070367983</td>\n",
       "      <td>good_reads:book</td>\n",
       "      <td>https://www.goodreads.com/author/show/7732.Mar...</td>\n",
       "      <td>1968</td>\n",
       "      <td>/genres/fiction|/genres/historical-fiction|/ge...</td>\n",
       "      <td>dir57/953435.L_uvre_au_noir.html</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1601</td>\n",
       "      <td>L'Åuvre au noir</td>\n",
       "      <td>Marguerite_Yourcenar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating  review_count        isbn         booktype                                         author_url  year                                         genre_urls                                  dir genres genres genres  rating_count                name                author\n",
       "1014     4.0           483  0374529264  good_reads:book  https://www.goodreads.com/author/show/7732.Mar...  1951  /genres/historical-fiction|/genres/fiction|/ge...  dir11/12172.Memoirs_of_Hadrian.html   None   None   None          6258  Memoirs of Hadrian  Marguerite_Yourcenar\n",
       "5620     4.0            74  2070367983  good_reads:book  https://www.goodreads.com/author/show/7732.Mar...  1968  /genres/fiction|/genres/historical-fiction|/ge...     dir57/953435.L_uvre_au_noir.html   None   None   None          1601    L'Åuvre au noir  Marguerite_Yourcenar"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.author == \"Marguerite_Yourcenar\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us delete the `genre_urls` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['genre_urls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then save the dataframe out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/cleaned-goodreads.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AppliedDataScience/lib/python3.11/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AppliedDataScience/lib/python3.11/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[1;32m   3968\u001b[0m     path_or_buf,\n\u001b[1;32m   3969\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   3970\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[1;32m   3971\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   3972\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   3973\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m   3974\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[1;32m   3975\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   3976\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[1;32m   3977\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   3978\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m   3979\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[1;32m   3980\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[1;32m   3981\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[1;32m   3982\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[1;32m   3983\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m   3984\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AppliedDataScience/lib/python3.11/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AppliedDataScience/lib/python3.11/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    254\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    255\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[1;32m    256\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[1;32m    257\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[1;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AppliedDataScience/lib/python3.11/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     check_parent_directory(\u001b[38;5;28mstr\u001b[39m(handle))\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AppliedDataScience/lib/python3.11/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'data'"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"data/cleaned-goodreads.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Grouping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that some books were written in negative years!  Print out the observations that correspond to negative years.  What do you notice about these books?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47                               The Odyssey\n",
       "246                    The Iliad/The Odyssey\n",
       "455                             The Republic\n",
       "596                               The Aeneid\n",
       "629                              Oedipus Rex\n",
       "674                           The Art of War\n",
       "746                        The Bhagavad Gita\n",
       "777                                 Antigone\n",
       "1233                       The Oedipus Cycle\n",
       "1397                          Aesop's Fables\n",
       "1398                   The Epic of Gilgamesh\n",
       "1428                                   Medea\n",
       "1815                            The Oresteia\n",
       "1882         The Trial and Death of Socrates\n",
       "2078    The History of the Peloponnesian War\n",
       "2527                           The Histories\n",
       "3133                          Complete Works\n",
       "3274                  The Nicomachean Ethics\n",
       "3757                              Lysistrata\n",
       "4402                           The Symposium\n",
       "4475                                 Apology\n",
       "5367                          Five Dialogues\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.year < 0].name\n",
    "#These are books written before the Common Era (BCE, equivalent to BC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can determine the \"best book\" by year! For this we use Panda's `groupby()`. `Groupby()` allows grouping a dataframe by any (usually categorical) variable. Would it make sense to ever groupby integer variables? Floating point variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.groupby.generic.DataFrameGroupBy"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfgb_author = df.groupby('author')\n",
    "type(dfgb_author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps we want the number of books each author wrote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>booktype</th>\n",
       "      <th>author_url</th>\n",
       "      <th>year</th>\n",
       "      <th>dir</th>\n",
       "      <th>genres</th>\n",
       "      <th>genres</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A_A_Milne</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_G_Howard</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_J_Cronin</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_J_Jacobs</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_J_Salt</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_gota_Krist_f</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_mile_Zola</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_ric_Emmanuel_Schmitt</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_sne_Seierstad</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2645 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       rating  review_count  isbn  booktype  author_url  year  dir  genres  genres  genres  rating_count  name\n",
       "author                                                                                                                        \n",
       "A_A_Milne                   6             6     6         6           6     6    6       0       0       0             6     6\n",
       "A_G_Howard                  1             1     1         1           1     1    1       0       0       0             1     1\n",
       "A_J_Cronin                  1             1     1         1           1     1    1       0       0       0             1     1\n",
       "A_J_Jacobs                  1             1     1         1           1     1    1       0       0       0             1     1\n",
       "A_J_Salt                    1             1     1         1           1     1    1       0       0       0             1     1\n",
       "...                       ...           ...   ...       ...         ...   ...  ...     ...     ...     ...           ...   ...\n",
       "_                          42            42    42        42          42    42   42       0       0       0            42    42\n",
       "_gota_Krist_f               1             1     1         1           1     1    1       0       0       0             1     1\n",
       "_mile_Zola                  4             4     4         4           4     4    4       0       0       0             4     4\n",
       "_ric_Emmanuel_Schmitt       1             1     1         1           1     1    1       0       0       0             1     1\n",
       "_sne_Seierstad              1             1     1         1           1     1    1       0       0       0             1     1\n",
       "\n",
       "[2645 rows x 12 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfgb_author.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of useless info there. One column should suffice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "- Group the dataframe by `author`. Include the following columns: `rating`, `name`, `author`. For the aggregation of the `name` column which includes the names of the books create a list with the strings containing the name of each book. Make sure that the way you aggregate the rest of the columns make sense! \n",
    "\n",
    "- Create a new column with number of books for each author and find the most prolific author!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Before we start : what do we do about these titles where 'name' is unreadable? Try different encodings?\n",
    "auth_name = 'A_id_al_Qarni'\n",
    "df[df.author == auth_name].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.author == auth_name].iat[0,8].encode('UTF-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's examine the columns we have\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the GroupBy table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = df.copy()\n",
    "authors = authors[['rating','name','author']].groupby('author').agg({'rating' : np.mean,\n",
    "                                                                    'name' : '|'.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = authors.reset_index()\n",
    "authors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the column string and make a list of string book names\n",
    "authors['name'] = authors.name.str.split('|')\n",
    "authors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the books - create new column\n",
    "len(authors.name[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors['num_books'] = authors['name'].str.len()\n",
    "authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort for more prolific\n",
    "authors.sort_values(by='num_books', ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Winner is Stephen King with 56 books! OMG!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps you want more detailed info..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfgb_author[['rating', 'rating_count', 'review_count', 'year']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also access a `groupby` dictionary style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingdict = {}\n",
    "for author, subset in dfgb_author:\n",
    "    ratingdict[author] = (subset['rating'].mean(), subset['rating'].std())\n",
    "ratingdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This question is primarily aimed at graduate students, serving as a critical part of their assignment. However, undergraduate students are encouraged to take this on as an optional bonus challenge.**\n",
    "<div class=\"exercise\"><b>Exercise 7</b></div>\n",
    "\n",
    "Lets get the best-rated book(s) for every year in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using .groupby, we can divide the dataframe into subsets by the values of 'year'.\n",
    "#We can then iterate over these subsets\n",
    "# your code here\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
