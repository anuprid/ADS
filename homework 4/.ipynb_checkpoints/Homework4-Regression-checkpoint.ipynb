{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='heading'>\n",
    "    <div style='float:left;'><h1>CPSC 4300/6300: Applied Data Science</h1></div>\n",
    "    <img style=\"float: right; padding-right: 10px; width: 65px\" src=\"https://bsethwalker.github.io/assets/img/clemson_paw.png\"> </div><br>\n",
    "\n",
    "## Week 4: Regressions\n",
    "\n",
    "**Clemson University**<br>\n",
    "**Spring 2024**<br>\n",
    "**Instructor(s):** Nina Hubig <br>\n",
    "**TA(s):** Luyi Li\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "\n",
       "div.heading {\n",
       "margin-bottom: 25px;\n",
       "height: 75px;\n",
       "}\n",
       "\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "    \n",
       "    background: rgba(245, 102, 0, .75);\n",
       "    border-color: #E9967A;\n",
       "    border-left: 5px solid #522D80; \n",
       "    padding: 0.5em;\n",
       "}\n",
       "\n",
       "div.exercise-r {\n",
       "    background-color: #fce8e8;\n",
       "    border-color: #E9967A; \t\n",
       "    border-left: 5px solid #800080; \n",
       "    padding: 0.5em;\n",
       "}\n",
       "\n",
       "span.sub-q {\n",
       "    font-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "    background-color: #DDDDDD;\n",
       "    border-color: #E9967A; \t\n",
       "    border-left: 5px solid #800080; \n",
       "    padding: 0.5em;\n",
       "    font-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "    background-color: #AEDE94;\n",
       "    border-color: #E9967A; \t \n",
       "    border-left: 5px solid #800080; \n",
       "    padding: 0.5em;\n",
       "    font-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RUN THIS CELL TO GET THE RIGHT FORMATTING \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://bsethwalker.github.io/assets/css/cpsc6300.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "* Feel comfortable with simple linear regression\n",
    "* Feel comfortable with polynomial regression\n",
    "* Feel comfortable with multiple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "## 1 - Simple Linear Regression\n",
    "\n",
    "Linear regression and its many extensions are a workhorse of the statistics and data science community, both in application and as a reference point for other models. Most of the major concepts in machine learning can be and often are discussed in terms of various linear regression models. Thus, this section will introduce you to building and fitting linear regression models and some of the process behind it, so that you can 1) fit models to data you encounter 2) experiment with different kinds of linear regression and observe their effects 3) see some of the technology that makes regression models work.\n",
    "\n",
    "\n",
    "### Linear regression with a toy dataset\n",
    "We first examine a toy problem, focusing our efforts on fitting a linear model to a small dataset with three observations.  Each observation consists of one predictor $x_i$ and one response $y_i$ for $i = 1, 2, 3$,\n",
    "\n",
    "\\begin{align*}\n",
    "(x , y) = \\{(x_1, y_1), (x_2, y_2), (x_3, y_3)\\}.\n",
    "\\end{align*}\n",
    "\n",
    "To be very concrete, let's set the values of the predictors and responses.\n",
    "\n",
    "\\begin{equation*}\n",
    "(x , y) = \\{(1, 2), (2, 2), (3, 4)\\}\n",
    "\\end{equation*}\n",
    "\n",
    "There is no line of the form $\\beta_0 + \\beta_1 x = y$ that passes through all three observations, since the data are not collinear. Thus our aim is to find the line that best fits these observations in the *least-squares sense*, as discussed in lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 1</b></div>\n",
    "\n",
    "* Make two numpy arrays out of this data, x_train and y_train\n",
    "* Check the dimentions of these arrays\n",
    "* Try to reshape them into a different shape\n",
    "* Make points into a very simple scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A better scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m     ax\u001b[38;5;241m.\u001b[39mlegend(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize \u001b[38;5;241m=\u001b[39m f_size)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ax\n\u001b[0;32m---> 34\u001b[0m nice_scatterplot(x_train, y_train, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhello nice plot\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "def nice_scatterplot(x, y, title):\n",
    "    # font size\n",
    "    f_size = 18\n",
    "    \n",
    "    # make the figure\n",
    "    fig, ax = plt.subplots(1,1, figsize=(8,5)) # Create figure object\n",
    "\n",
    "    # set axes limits to make the scale nice\n",
    "    ax.set_xlim(np.min(x)-1, np.max(x) + 1)\n",
    "    ax.set_ylim(np.min(y)-1, np.max(y) + 1)\n",
    "\n",
    "    # adjust size of tickmarks in axes\n",
    "    ax.tick_params(labelsize = f_size)\n",
    "    \n",
    "    # remove tick labels\n",
    "    #ax.tick_params(labelbottom=False, bottom=False)\n",
    "    \n",
    "    # adjust size of axis label\n",
    "    ax.set_xlabel(r'$x$', fontsize = f_size)\n",
    "    ax.set_ylabel(r'$y$', fontsize = f_size)\n",
    "    \n",
    "    # set figure title label\n",
    "    ax.set_title(title, fontsize = f_size)\n",
    "\n",
    "    # you may set up grid with this \n",
    "    ax.grid(True, lw=1.75, ls='--', alpha=0.15)\n",
    "\n",
    "    # make actual plot (Notice the label argument!)\n",
    "    ax.scatter(x, y, label=r'$my points$')\n",
    "    ax.legend(loc='best', fontsize = f_size)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "nice_scatterplot(x_train, y_train, 'hello nice plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Formulae\n",
    "Linear regression is special among the models we study because it can be solved explicitly. While most other models (and even some advanced versions of linear regression) must be solved itteratively, linear regression has a formula where you can simply plug in the data.\n",
    "\n",
    "For the single predictor case it is:\n",
    "$\\beta_1 = \\frac{\\sum_{i=1}^n{(x_i-\\bar{x})(y_i-\\bar{y})}}{\\sum_{i=1^n{(x_i-\\bar{x})^2}}\\beta_0 = \\bar{y} - \\beta_1\\bar{x}}$\n",
    "    \n",
    "Where $\\bar{y}$ and $\\bar{x}$ are the mean of the y values and the mean of the x values, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Building a model from scratch\n",
    "In this part, we will solve the equations for simple linear regression and find the best fit solution to our toy problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The snippets of code below implement the linear regression equations on the observed predictors and responses, which we'll call the training data set.  Let's walk through the code.\n",
    "\n",
    "We have to reshape our arrrays to 2D. We will see later why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 2</b></div>\n",
    "\n",
    "* make an array with shape (2,3)\n",
    "* reshape it to a size that you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE AN ARRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESHAPE THE ARRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, compute means\n",
    "y_bar = np.mean(y_train)\n",
    "x_bar = np.mean(x_train)\n",
    "\n",
    "# build the two terms\n",
    "numerator = np.sum( (x_train - x_bar)*(y_train - y_bar) )\n",
    "denominator = np.sum((x_train - x_bar)**2)\n",
    "\n",
    "print(numerator.shape, denominator.shape) #check shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Why the empty brackets? (The numerator and denominator are scalars, as expected.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slope beta1\n",
    "beta_1 = numerator/denominator\n",
    "\n",
    "#intercept beta0\n",
    "beta_0 = y_bar - beta_1*x_bar\n",
    "\n",
    "print(\"The best-fit line is {0:3.2f} + {1:3.2f} * x\".format(beta_0, beta_1))\n",
    "print(f'The best fit is {beta_0}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 3</b></div>\n",
    "\n",
    "Turn the code from the above cells into a function called `simple_linear_regression_fit`, that inputs the training data and returns `beta0` and `beta1`.\n",
    "\n",
    "To do this, copy and paste the code from the above cells below and adjust the code as needed, so that the training data becomes the input and the betas become the output.\n",
    "\n",
    "```python\n",
    "def simple_linear_regression_fit(x_train: np.ndarray, y_train: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    return\n",
    "```\n",
    "\n",
    "Check your function by calling it with the training data from above and printing out the beta values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simple_linear_regression_fit(x_train: np.ndarray, y_train: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    x_train: a (num observations by 1) array holding the values of the predictor variable\n",
    "    y_train: a (num observations by 1) array holding the values of the response variable\n",
    "\n",
    "    Returns:\n",
    "    beta_vals:  a (num_features by 1) array holding the intercept and slope coeficients\n",
    "    \"\"\"\n",
    "    # WRITE YOUR CODE HERE\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's run this function and see the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([1 ,2, 3])\n",
    "y_train = np.array([2, 2, 4])\n",
    "\n",
    "betas = simple_linear_regression_fit(x_train, y_train)\n",
    "\n",
    "beta_0 = betas[0]\n",
    "beta_1 = betas[1]\n",
    "\n",
    "print(\"The best-fit line is {0:8.6f} + {1:8.6f} * x\".format(beta_0, beta_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 4</b></div>\n",
    "\n",
    "* Do the values of `beta0` and `beta1` seem reasonable?\n",
    "* Plot the training data using a scatter plot.\n",
    "* Plot the best fit line with `beta0` and `beta1` together with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of `beta0` and `beta1` seem roughly reasonable.  They capture the positive correlation.  The line does appear to be trying to get as close as possible to all the points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"fourth-bullet\"></a>\n",
    "## 3 - Building a model with `statsmodels` and `sklearn`\n",
    "\n",
    "Now that we can concretely fit the training data from scratch, let's learn two `python` packages to do it all for us:\n",
    "* [statsmodels](http://www.statsmodels.org/stable/regression.html) and \n",
    "* [scikit-learn (sklearn)](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n",
    "\n",
    "Our goal  is to show how to implement simple linear regression with these packages.  For an important sanity check, we compare the $\\beta$ values from `statsmodels` and `sklearn` to the $\\beta$ values that we found from above with our own implementation.\n",
    "\n",
    "For the purposes of this lab, `statsmodels` and `sklearn` do the same thing.  More generally though, `statsmodels` tends to be easier for inference \\[finding the values of the slope and intercept and dicussing uncertainty in those values\\], whereas `sklearn` has machine-learning algorithms and is better for prediction \\[guessing y values for a given x value\\]. (Note that both packages make the same guesses, it's just a question of which activity they provide more support for.\n",
    "\n",
    "**Note:** `statsmodels` and `sklearn` are different packages!  Unless we specify otherwise, you can use either one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code for `statsmodels`.  `Statsmodels` does not by default include the column of ones in the $X$ matrix, so we include it manually with `sm.add_constant`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the X matrix by appending a column of ones to x_train\n",
    "X = sm.add_constant(x_train)\n",
    "\n",
    "# this is the same matrix as in our scratch problem!\n",
    "print(X)\n",
    "\n",
    "# build the OLS model (ordinary least squares) from the training data\n",
    "toyregr_sm = sm.OLS(y_train, X)\n",
    "\n",
    "# do the fit and save regression info (parameters, etc) in results_sm\n",
    "results_sm = toyregr_sm.fit()\n",
    "\n",
    "# pull the beta parameters out from results_sm\n",
    "beta0_sm = results_sm.params[0]\n",
    "beta1_sm = results_sm.params[1]\n",
    "\n",
    "print(f'The regression coef from statsmodels are: beta_0 = {beta0_sm:8.6f} and beta_1 = {beta1_sm:8.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the beta parameters, `results_sm` contains a ton of other potentially useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "print(results_sm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's turn our attention to the `sklearn` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build the least squares model\n",
    "toyregr = linear_model.LinearRegression()\n",
    "\n",
    "# save regression info (parameters, etc) in results_skl\n",
    "results = toyregr.fit(x_train, y_train)\n",
    "\n",
    "# pull the beta parameters out from results_skl\n",
    "beta0_skl = toyregr.intercept_\n",
    "beta1_skl = toyregr.coef_[0]\n",
    "\n",
    "print(\"The regression coefficients from the sklearn package are: beta_0 = {0:8.6f} and beta_1 = {1:8.6f}\".format(beta0_skl, beta1_skl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `scikit-learn` library and the shape of things\n",
    "\n",
    "Before diving into a \"real\" problem, let's discuss more of the details of `sklearn`.\n",
    "\n",
    "`Scikit-learn` is the main `Python` machine learning library. It consists of many learners which can learn models from data, as well as a lot of utility functions such as `train_test_split()`. \n",
    "\n",
    "Use the following to add the library into your code:\n",
    "\n",
    "```python\n",
    "import sklearn \n",
    "```\n",
    "\n",
    "In `scikit-learn`, an **estimator** is a Python object that implements the methods `fit(X, y)` and `predict(T)`\n",
    "\n",
    "Let's see the structure of `scikit-learn` needed to make these fits. `fit()` always takes two arguments:\n",
    "```python\n",
    "estimator.fit(Xtrain, ytrain)\n",
    "```\n",
    "We will consider two estimators in this lab: `LinearRegression` and `KNeighborsRegressor`.\n",
    "\n",
    "It is very important to understand that `Xtrain` must be in the form of a **2x2 array** with each row corresponding to one sample, and each column corresponding to the feature values for that sample.\n",
    "\n",
    "`ytrain` on the other hand is a simple array of responses.  These are continuous for regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice with `sklearn` and a real dataset\n",
    "We begin by loading up the `mtcars` dataset. This data was extracted from the 1974 Motor Trend US magazine, and comprises of fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models). We will load this data to a dataframe with 32 observations on 11 (numeric) variables. Here is an explanation of the features:\n",
    "\n",
    "- `mpg` is Miles/(US) gallon \n",
    "- `cyl` is Number of cylinders, \n",
    "- `disp` is\tDisplacement (cu.in.), \n",
    "- `hp` is\tGross horsepower, \n",
    "- `drat` is\tRear axle ratio, \n",
    "- `wt` is the Weight (1000 lbs), \n",
    "- `qsec` is 1/4 mile time,\n",
    "- `vs` is Engine (0 = V-shaped, 1 = straight), \n",
    "- `am` is Transmission (0 = automatic, 1 = manual), \n",
    "- `gear` is the Number of forward gears, \n",
    "- `carb` is\tNumber of carburetors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load mtcars\n",
    "dfcars = pd.read_csv(\"mtcars.csv\")\n",
    "dfcars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the column title \n",
    "dfcars = dfcars.rename(columns={\"Unnamed: 0\":\"car name\"})\n",
    "dfcars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Searching for values: how many cars have 4 gears?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(dfcars[dfcars.gear == 4].drop_duplicates(subset='car name', keep='first'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's split the dataset into a training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set random_state to get the same split every time\n",
    "traindf, testdf = train_test_split(dfcars, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing set is around 20% of the total data; training set is around 80%\n",
    "print(\"Shape of full dataset is: {0}\".format(dfcars.shape))\n",
    "print(\"Shape of training dataset is: {0}\".format(traindf.shape))\n",
    "print(\"Shape of test dataset is: {0}\".format(testdf.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have training and test data.  We still need to select a predictor and a response from this dataset.  Keep in mind that we need to choose the predictor and response from both the training and test set.  You will do this in the exercises below.  However, we provide some starter code for you to get things going."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the response variable that we're interested in\n",
    "y_train = traindf.mpg\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, notice the shape of `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, type(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array reshape\n",
    "This is a 1D array as should be the case with the **Y** array.  Remember, `sklearn` requires a 2D array only for the predictor array.  You will have to pay close attention to this in the exercises later. `Sklearn` doesn't care too much about the shape of `y_train`.\n",
    "\n",
    "The whole reason we went through that whole process was to show you how to reshape your data into the correct format.\n",
    "\n",
    "**IMPORTANT:** Remember that your response variable `ytrain` can be a vector but your predictor variable `xtrain` ***must*** be an array!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"fifth-bullet\"></a>\n",
    "## 3 - Example: Simple linear regression with automobile data\n",
    "We will now use `sklearn` to predict automobile mileage per gallon (mpg) and evaluate these predictions. We already loaded the data and split them into a training set and a test set.\n",
    "\n",
    "We need to choose the variables that we think will be good predictors for the dependent variable `mpg`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 5</b></div>\n",
    "\n",
    "* Pick one variable to use as a predictor for simple linear regression.  Discuss your reasons with the person next to you.  \n",
    "* Justify your choice with some visualizations.  \n",
    "* Is there a second variable you'd like to use? For example, we're not doing multiple linear regression here, but if we were, is there another variable you'd like to include if we were using two predictors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 6</b></div>\n",
    "\n",
    "* Use `sklearn` to fit the training data using simple linear regression.\n",
    "* Use the model to make mpg predictions on the test set.  \n",
    "* Plot the data and the prediction.  \n",
    "* Print out the mean squared error for the training set and the test set and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcars = pd.read_csv('mtcars.csv')\n",
    "dfcars = dfcars.rename(columns={\"Unnamed: 0\":\"name\"})\n",
    "\n",
    "dfcars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression, and Cab Data\n",
    "\n",
    "Polynomial regression uses a **linear model** to estimate a **non-linear function** (i.e., a function with polynomial terms). For example:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_i + \\beta_1x_i^{2}$\n",
    "\n",
    "It is a linear model because we are still solving a linear equation (the _linear_ aspect refers to the beta coefficients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data, break into train and test\n",
    "cab_df = pd.read_csv(\"data/cabs.txt\")\n",
    "train_data, test_data = train_test_split(cab_df, test_size=.2, random_state=42)\n",
    "cab_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cab_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some data cleaning\n",
    "X_train = train_data['TimeMin'].values.reshape(-1,1)/60 # transforms it to being hour-based\n",
    "y_train = train_data['PickupCount'].values\n",
    "\n",
    "X_test = test_data['TimeMin'].values.reshape(-1,1)/60 # hour-based\n",
    "y_test = test_data['PickupCount'].values\n",
    "\n",
    "def plot_cabs(cur_model, poly_transformer=None):\n",
    "    \n",
    "    # build the x values for the prediction line\n",
    "    x_vals = np.arange(0,24,.1).reshape(-1,1)\n",
    "    \n",
    "    # optionally use the passed-in transformer\n",
    "    if poly_transformer != None:\n",
    "        dm = poly_transformer.fit_transform(x_vals)\n",
    "    else:\n",
    "        dm = x_vals\n",
    "        \n",
    "    # make the prediction at each x value\n",
    "    prediction = cur_model.predict(dm)\n",
    "    \n",
    "    # plot the prediction line, and the test data\n",
    "    plt.plot(x_vals,prediction, color='k', label=\"Prediction\")\n",
    "    plt.scatter(X_test, y_test, label=\"Test Data\")\n",
    "\n",
    "    # label your plots\n",
    "    plt.ylabel(\"Number of Taxi Pickups\")\n",
    "    plt.xlabel(\"Time of Day (Hours Past Midnight)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_cab_model0 = LinearRegression().fit(X_train, y_train)\n",
    "plot_cabs(fitted_cab_model0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_cab_model0.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This question is primarily aimed at graduate students, serving as a critical part of their assignment. However, undergraduate students are encouraged to take this on as an optional bonus challenge.**\n",
    "<div class=\"exercise\"><b>Exercise 7</b></div>\n",
    "\n",
    "\n",
    "1. The above code uses `sklearn`. As more practice, and to help you stay versed in both libraries, perform the same task (fit a linear regression line) using `statsmodels` and report the $r^2$ score. Is it the same value as what sklearn reports, and is this the expected behavior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there's still a lot of variation in cab pickups that's not being captured by a linear fit. Further, the linear fit is predicting massively more pickups at 11:59pm than at 12:00am. This is a bad property, and it's the conseqeuence of having a straight line with a non-zero slope. However, we can add columns to our data for $TimeMin^2$ and $TimeMin^3$ and so on, allowing a curvy polynomial line to hopefully fit the data better.\n",
    "\n",
    "We'll be using ``sklearn``'s `PolynomialFeatures()` function to take some of the tedium out of building the expanded input data. In fact, if all we want is a formula like $y \\approx \\beta_0 + \\beta_1 x + \\beta_2 x^2 + ...$, it will directly return a new copy of the data in this format!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_3 = PolynomialFeatures(3, include_bias=False)\n",
    "expanded_train = transformer_3.fit_transform(X_train) # TRANSFORMS it to polynomial features\n",
    "pd.DataFrame(expanded_train).describe() # notice that the columns now contain x, x^2, x^3 values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few notes on `PolynomialFeatures`:\n",
    "\n",
    "- The interface is a bit strange. `PolynomialFeatures` is a _'transformer'_ in sklearn. We'll be using several transformers that learn a transformation on the training data, and then we will apply those transformations on future data. With PolynomialFeatures, the `.fit()` is pretty trivial, and we often fit and transform in one command, as seen above with ``.fit_transform()`.\n",
    "- You rarely want to `include_bias` (a column of all 1's), since _**sklearn**_ will add it automatically. Remember, when using _**statsmodels,**_ you can just `.add_constant()` right before you fit the data.\n",
    "- If you want polynomial features for a several different variables (i.e., multinomial regression), you should call `.fit_transform()` separately on each column and append all the results to a copy of the data (unless you also want interaction terms between the newly-created features). See `np.concatenate()` for joining arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_cab_model3 = LinearRegression().fit(expanded_train, y_train)\n",
    "print(\"fitting expanded_train:\", expanded_train)\n",
    "plot_cabs(fitted_cab_model3, transformer_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 8</b></div>\n",
    "\n",
    "**Questions**:\n",
    "1. Calculate the polynomial model's $R^2$ performance on the test set. \n",
    "2. Does the polynomial model improve on the purely linear model?\n",
    "3. Make a residual plot for the polynomial model. What does this plot tell us about the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other features\n",
    "Polynomial features are not the only constucted features that help fit the data. Because these data have a 24 hour cycle, we may want to build features that follow such a cycle. For example, $sin(24\\frac{x}{2\\pi})$, $sin(12\\frac{x}{2\\pi})$, $sin(8\\frac{x}{2\\pi})$. Other feature transformations are appropriate to other types of data. For instance certain feature transformations have been developed for geographical data.\n",
    "\n",
    "### Scaling Features\n",
    "When using polynomials, we are explicitly trying to use the higher-order values for a given feature. However, sometimes these polynomial features can take on values that are drastically large, making it difficult for the system to learn an appropriate bias weight due to its large values and potentially large variance. To counter this, sometimes one may be interested in scaling the values for a given feature.\n",
    "\n",
    "For our ongoing taxi-pickup example, using polynomial features improved our model. If we wished to scale the features, we could use `sklearn`'s StandardScaler() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALES THE EXPANDED/POLY TRANSFORMED DATA\n",
    "# we don't need to convert to a pandas dataframe, but it can be useful for scaling select columns\n",
    "train_copy = pd.DataFrame(expanded_train.copy())\n",
    "test_copy = pd.DataFrame(expanded_test.copy())\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "scaler = StandardScaler().fit(train_copy)\n",
    "\n",
    "# Scale both the test and training data. \n",
    "train_scaled = scaler.transform(expanded_train)\n",
    "test_scaled = scaler.transform(expanded_test)\n",
    "\n",
    "# we could optionally run a new regression model on this scaled data\n",
    "fitted_scaled_cab = LinearRegression().fit(train_scaled, y_train)\n",
    "fitted_scaled_cab.score(test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px\">\n",
    "\n",
    "## Multiple regression and exploring the Football (aka soccer) data\n",
    "Let's move on to a different dataset! The data imported below were scraped by [Shubham Maurya](https://www.kaggle.com/mauryashubham/linear-regression-to-predict-market-value/data) and record various facts about players in the English Premier League. Our goal will be to fit models that predict the players' market value (what the player could earn when hired by a new team), as estimated by https://www.transfermarkt.us.\n",
    "\n",
    "`name`: Name of the player  \n",
    "`club`: Club of the player  \n",
    "`age` : Age of the player  \n",
    "`position` : The usual position on the pitch  \n",
    "`position_cat` :  1 for attackers, 2 for midfielders, 3 for defenders, 4 for goalkeepers  \n",
    "`market_value` : As on www.transfermarkt.us.on July 20th, 2017  \n",
    "`page_views` : Average daily Wikipedia page views from September 1, 2016 to May 1, 2017  \n",
    "`fpl_value` : Value in Fantasy Premier League as on July 20th, 2017  \n",
    "`fpl_sel` : % of FPL players who have selected that player in their team  \n",
    "`fpl_points` : FPL points accumulated over the previous season  \n",
    "`region`: 1 for England, 2 for EU, 3 for Americas, 4 for Rest of World  \n",
    "`nationality`: Player's nationality  \n",
    "`new_foreign`: Whether a new signing from a different league, for 2017/18 (till 20th July)  \n",
    "`age_cat`: a categorical version of the Age feature  \n",
    "`club_id`: a numerical version of the Club feature  \n",
    "`big_club`: Whether one of the Top 6 clubs  \n",
    "`new_signing`: Whether a new signing for 2017/18 (till 20th July)  \n",
    "\n",
    "As always, we first import, verify, split, and explore the data.\n",
    "\n",
    "## Part 1: Import and verification and grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "league_df = pd.read_csv(\"league_data.txt\")\n",
    "print(league_df.dtypes)\n",
    "\n",
    "# QUESTION: what would you guess is the mean age? mean salary?\n",
    "league_df.head() # turns out, it's a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "league_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "league_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Stratified) train/test split\n",
    "We want to make sure that the training and test data have appropriate representation of each region; it would be bad for the training data to entirely miss a region. This is especially important because some regions are rather rare.\n",
    "\n",
    "\n",
    "**This question is primarily aimed at graduate students, serving as a critical part of their assignment. However, undergraduate students are encouraged to take this on as an optional bonus challenge.**\n",
    "<div class=\"exercise\"><b>Exercise 9</b></div>\n",
    "\n",
    "1. Use the `train_test_split()` function, while (a) ensuring the test size is 20% of the data, and; (2) using 'stratify' argument to split the data (look up documentation online), keeping equal representation of each region. This doesn't work by default, correct? What is the issue?\n",
    "2. Deal with the issue you encountered above. Hint: you may find numpy's `.isnan()` and panda's `.dropna()` functions useful!\n",
    "3. How did you deal with the error generated by `train_test_split`? How did you justify your action? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we won't be peeking at the test set, let's explore and look for patterns! We'll introduce a number of useful pandas and numpy functions along the way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby\n",
    "Pandas' `.groupby()` function is a wonderful tool for data analysis. It allows us to analyze each of several subgroups.\n",
    "\n",
    "Many times, `.groupby()` is combined with `.agg()` to get a summary statistic for each subgroup. For instance: What is the average market value, median page views, and maximum fpl for each player position?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.groupby('position').agg({\n",
    "    'market_value': np.mean,\n",
    "    'page_views': np.median,\n",
    "    'fpl_points': np.max\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.position.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.groupby(['big_club', 'position']).agg({\n",
    "    'market_value': np.mean,\n",
    "    'page_views': np.mean,\n",
    "    'fpl_points': np.mean\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 10</b></div>\n",
    "\n",
    "**Question**:\n",
    "1. Notice that the `.groupby()` function above takes a list of two column names. Does the order matter? What happens if we switch the two so that 'position' is listed before 'big_club'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px\">\n",
    "\n",
    "## Part 2: Linear regression on the football data\n",
    "This section of the lab focuses on fitting a model to the football (soccer) data and interpreting the model results. The model we'll use is\n",
    "\n",
    "$$\\text{market_value} \\approx \\beta_0 + \\beta_1\\text{fpl_points} + \\beta_2\\text{age} + \\beta_3\\text{age}^2 + \\beta_4log_2\\left(\\text{page_views}\\right) + \\beta_5\\text{new_signing} +\\beta_6\\text{big_club} + \\beta_7\\text{position_cat}$$\n",
    "\n",
    "We're including a 2nd degree polynomial in age because we expect pay to increase as a player gains experience, but then decrease as they continue aging. We're taking the log of page views because they have such a large, skewed range and the transformed variable will have fewer outliers that could bias the line. We choose the base of the log to be 2 just to make interpretation cleaner.\n",
    "\n",
    "**This question is primarily aimed at graduate students, serving as a critical part of their assignment. However, undergraduate students are encouraged to take this on as an optional bonus challenge.**\n",
    "<div class=\"exercise\"><b>Exercise 11</b></div>\n",
    "\n",
    "\n",
    "1. Build the data and fit this model to it. How good is the overall model?\n",
    "2. Interpret the regression model. What is the meaning of the coefficient for:\n",
    "    - age and age$^2$\n",
    "    - $log_2($page_views$)$\n",
    "    - big_club\n",
    "3. What should a player do in order to improve their market value? How many page views should a player go get to increase their market value by 10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2: your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3: your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:3px'>\n",
    "\n",
    "### Part 3: Turning Categorical Variables into multiple binary variables\n",
    "Of course, we have an error in how we've included player position. Even though the variable is numeric (1,2,3,4) and the model runs without issue, the value we're getting back is garbage. The interpretation, such as it is, is that there is an equal effect of moving from position category 1 to 2, from 2 to 3, and from 3 to 4, and that this effect is probably between -0.5 to -1 (depending on your run).\n",
    "\n",
    "In reality, we don't expect moving from one position category to another to be equivalent, nor for a move from category 1 to category 3 to be twice as important as a move from category 1 to category 2. We need to introduce better features to model this variable.\n",
    "\n",
    "We'll use `pd.get_dummies` to do the work for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_design_recoded = pd.get_dummies(train_transformed, columns=['position_cat'], drop_first=True)\n",
    "test_design_recoded = pd.get_dummies(test_transformed, columns=['position_cat'], drop_first=True)\n",
    "\n",
    "train_design_recoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resu = OLS(y_train, train_design_recoded).fit()\n",
    "resu.summary()\n",
    "print(\"r2:\", r2_score(y_test, resu.predict(test_design_recoded)))\n",
    "print(\"position_cat_2 coef:\", resu.params.position_cat_2)\n",
    "train_design_recoded.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. If our model does not have a constant, we must include all four dummy variable columns. If we drop one, we're not modeling any effect of being in that category, and effectively assuming the dropped category's effect is 0.\n",
    "2. Being in position 2 (instead of position 1) has an impact between -1.54 and +2.38 on a player's market value. Since we're using an intercept, the dropped category becomes the baseline and the effect of any dummy variable is the effect of being in that category instead of the baseline category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A nice trick for forward-backwards\n",
    "\n",
    "XOR (operator ^) is a logical operation that only returns true when input differ. We can use it to implement forward-or-backwards selection when we want to keep track of what predictors are \"left\" from a given list of predictors.\n",
    "\n",
    "The set analog is \"symmetric difference\". From the python docs:\n",
    "\n",
    "`s.symmetric_difference(t)\ts ^ t\tnew set with elements in either s or t but not both`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set() ^ set([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([1]) ^ set([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([1, 2]) ^ set([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57990f1ad2ea89c67ddae7f31d40c478205c5912da0fccfb7c5cfbb2b8bf17ad"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
